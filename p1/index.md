[【トップページへ戻る】](../)
# 1. バグを予測する
本課題は，ソフトウェア工学をデータサイエンス的な視点でとらえた際の「1.収集」「2.分析」「3.活用」のうち，「3.活用」のセクションに含まれます．
- 本課題の目的は機械学習を用いたバグ予測の実践です．
	- 解答例では以下の環境を使用しています．
    	- Python3
    	- scikit-learn（機械学習ライブラリ）
    	- pandas（データ解析支援・操作ライブラリ）
	- matplotlib（グラフ描画ライブラリ）
- 本課題では，データセット共有サービスであるZenodo（ https://zenodo.org ）からダウンロードし，予測に適した形に加工してデータセットとして使用します．
	- Apacheのgroovyというツールにおけるコミット履歴をデータとして使用します．
        - 2015年以前のコミットを学習データ，2016年以降のコミットを予測対象としてバグ含有コミットの予測を行い，その性能を評価することを最終的なゴールとします．
 
## 問1. データセットの読み込みと確認
1. https://zenodo.org/records/5907847 からapachejit_dataset_replication.zipをダウンロードしてください.
1. zipファイルを展開し，apachejit/dataset/apachejit_train.csvがあるのを確認して下さい．
1. apachejit_train.csvをpandas.DataFrameとして読み込み，ラベル（要素の名前）の一覧を表示してください．
1. データの行と列の数を確認してください．
	- データはラベル行抜きで**44,834行18列**あります（44,834データ，1データにつき18要素が含まれることを意味します）．
1. project列の値がapache/groovyの行のみを表示してください．
1. project列の値がapache/groovyの行について，以下を実施してください．
    1. laという名前の変数だけを抽出してください
    1. laという名前の変数のヒストグラムを描画してください
    1. buggyという名前の変数だけを抽出して，円グラフを描画してください


## 問2. データの切り出しと変形
1. 問1で読み込んだデータテーブルから，project列の値がapache/groovyの行を切り出し，以下に指定する予測および学習に用いる変数（説明変数+目的変数）のみを切り出したデータテーブルを作成してください．
	- 目的変数：buggy
		- バグの有無（TRUEはバグあり，FALSEはバグなし）
	- 説明変数のメトリクス: la, ld, nf, nd, ns
		- それ以外のメトリクスの出典については[文献[1]](https://posl.ait.kyushu-u.ac.jp/~kamei/publications/Kamei_TSE2013.pdf)を参照のこと
  			- [1] Y. Kamei et al., "A large-scale empirical study of just-in-time quality assurance," in IEEE Transactions on Software Engineering, vol. 39, no. 6, pp. 757-773, June 2013.



|略称|説明|
|----|----|
|la|Lines of code added|
|ld|Lines of code deleted|
|nf|Number of modified files|
|nd|Number of modified directories|
|ns|Number of modified subststems|



1. 目的変数が0および1になるように変形してください．
1. 切り出したデータテーブルの行と列の数を確認してください


## 問3. 学習
- 作成したデータテーブルに対し，SVMを用いてバグの有無を学習モデルを構築します．
1. scikit-learnの`svm.SVC()`関数を用いてモデルを作成してください．パラメータは全てデフォルトでかまいません．
1. 作成したモデルに対し，`fit()`メソッドを用いてモデルにデータを与え，学習させてください．


## 問4. 予測
1. 問3で学習したモデルに対して，`predict()`メソッドを用いてバグの有無を予測してください．
	- 本来は学習データと評価データは区別すべきですが，とりあえずは問3で構築したモデルに問3の学習データをそのまま適用してください．
1. 予測結果として，バグありと予測されたデータの総数と，バグなしと予測されたデータの総数を集計してください．


## 問5. 混同行列
1. 問4の結果から混同行列を作成し，表示させてください．
	- 混同行列（Confusion Matrix）とは，二値分類タスクの評価で使用される2×2の行列です．
1. 予測結果が正しかったもの（True Positive，True Negative）を用いて正解率（TP+TN / ALL）を計算し，表示させてください．


## 問6. 適合率，再現率，F1スコア
1. 問5の混同行列から適合率および再現率，F1スコアを計算し，表示させてください．


## 問7 バグ確率の算出
1. SVMモデルの作成時に`probability=True`オプションを追加し，各データがバグを含む確率を算出してください．
1. 0.5を閾値として，バグを含む確率をもとにそれぞれのデータがバグを含むか否かを予測し，結果が問4の結果と等しくなることを確認しましょう．


## 問8. ROC曲線とAUC
1. scikit-learnの関数を使用し，問7で得た各データのバグ確率と正解ラベルを入力としてAUCを計算して表示させてください．
	- AUCは二値分類タスクの評価指標としてよく用いられる指標です．
	- ここでのAUCはROC曲線を用いて計算します．
1. ROC曲線をグラフとして出力させてください．

## 問9. バグ予測の実践
- データセットを学習用とテスト用に分割して，実際にバグ予測を行います．
	- apachejit_train.csvを入力データとします．
1. 入力データをyear列の値が2015より小さい（2015年以前）もの（学習用データ）と2016年のもの（テスト用データ）に分割してください（層別）
1. 分割したデータを用いて，問3の学習と問4の予測を行い，問5から問8の分析を実行して結果を表示させてください．

## 問10. 変数を増やす
1. ent, ndev, age, nuc, aexp, arex, asexpを説明変数として追加し，同様に予測して精度を比較してください．


## 問11. ハイパーパラメータチューニング
1. SVMモデルのハイパーパラメータ（C，kernel，他）を変更することで，予測の振る舞いは変化します．`GridSearchCV()`関数を用いたグリッドサーチを行い，全ての組み合わせによる評価を網羅的に実行し，最も精度の高いハイパーパラメータの組み合わせを示してください．

	- パラメータの候補には以下を使用してください．
```
tuned_parameters = [
    {'C': [1, 10, 100, 1000], 'kernel': ['linear']},
    {'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.001, 0.0001]}}
```

## 問12. モデルの変更（ランダムフォレスト）
1. 問3のモデル構築手法をSVMからランダムフォレストに変更して，同じ作業を行い，精度を比較しましょう

## 問13. 前処理
1. 再度，project列の値がapache/groovyの行についてlaという名前の変数だけを抽出し，ヒストグラムを描いてみましょう
1. 次に同じデータに対してMin-Max変換を行い，ヒストグラムを描いてみましょう
1. 同様にz-score変換を行い，ヒストグラムを描いてみましょう
1. 対数変換行い，ヒストグラムを描いてみましょう
1. 元のデータ，Min-Max変換後，z-score変換，対数変換後のヒストグラムを見比べて，対数変換以外のヒストグラムが同じ形状となることを確認しましょう

## 問14. 前処理を伴う予測
1. データセット全体に対してMin-Max変換，z-score変換，対数変換を行った上で問3から問6までの作業を行い，実験結果に差があるかを確認しましょう．

## 問15. その他の可視化
1. project列から2つを選び，それぞれデータを抽出し，age列を比較するために箱ひげ図を描きましょう

## その他
以下はバグ予測だと使う機会がないができておくと後で有用かと思われる内容です．余裕があれば自己学習の対象としてください．

- ダミー変数展開
- 欠損値処理
- 検定
